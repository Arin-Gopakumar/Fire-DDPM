# cfgs/ddpm/ddpm_full_run.yaml

# Configuration for the DDPM model (UNetConditional and GaussianDiffusion)
# This file defines the parameters passed to the model constructors.

model:
  class_path: models.ddpm_model.UNetConditional  # Path to the UNetConditional class
  init_args:
    image_size: 64                              # Must match data preparation
    in_target_channels: 1                       # Wildfire mask is single channel
    in_condition_channels: 115                  # Example: 5 days * 23 channels/day. Adjust based on your data.
    model_channels: 64                          # Base channels for UNet
    out_channels: 1                             # Output channels of UNet (matches target_channels)
    num_res_blocks: 2                           # Number of residual blocks
    channel_mult: [1, 2, 4, 8]                  # Channel multipliers for UNet depth
    time_emb_dim_mult: 4                        # Multiplier for time embedding dimension
    groups: 8                                   # GroupNorm groups

diffusion:
  class_path: models.ddpm_model.GaussianDiffusion # Path to the GaussianDiffusion class
  init_args:
    model: null                                 # This will be linked to the 'model' defined above by LightningCLI
    image_size: 64                              # Must match data preparation
    timesteps: 20                               # Number of diffusion timesteps
    beta_schedule_type: "linear"                # 'linear' or 'cosine'
    target_channels: 1                          # Wildfire mask is single channel

# Optimizer configuration (optional, can be in trainer config or directly in train.py)
optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 0.0001
    weight_decay: 0.01 # Common default for AdamW

# Loss function (optional, can be defined here or directly in the model/trainer)
# For diffusion models, the loss is typically handled internally by p_losses
# so this might not be directly used as a standalone loss.
# loss:
#   class_path: torch.nn.MSELoss # Example if you needed a separate MSE loss

# Data configuration (can be in a separate data_*.yaml file)
data:
  class_path: utils.dataset_loader.WildfireDataset
  init_args:
    data_dir: "../Fire-DDPM/data_2" # Path to your processed data
    image_size: [64, 64]
    split: "train" # This will be overridden in train.py for val/test
